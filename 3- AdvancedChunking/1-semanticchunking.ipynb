{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b5118d",
   "metadata": {},
   "source": [
    "### Semantic Chunking\n",
    "#### . Semantic chunker is a document splitter that uses similarity between sentences to decide chunk boundaries\n",
    "#### . It ensures that each chunk is semantically coherent and not cut off mid-thought like tranditional character/token splitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f17cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc23c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Chunks: \n",
      "\n",
      "Chunk 1:\n",
      "2 Langchain provides modular abstractions to combine LLM's with tools like OpenAI and Pinecone.\n",
      "\n",
      "Chunk 2:\n",
      "3 You can create chains, agents, memory and retrievers.\n",
      "\n",
      "Chunk 3:\n",
      "4 The Eiffel Tower is located in Paris.\n",
      "\n",
      "Chunk 4:\n",
      "5 France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "#initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "## Sample text\n",
    "text = \"\"\"\n",
    "1 Langchain is a framework for building applications with LLM's.\n",
    "2 Langchain provides modular abstractions to combine LLM's with tools like OpenAI and Pinecone.\n",
    "3 You can create chains, agents, memory and retrievers.\n",
    "4 The Eiffel Tower is located in Paris.\n",
    "5 France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "## Step 1 : Split into sentences\n",
    "sentences =[s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "## Step 2: Embed each sentence\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "## Step 3 : Initialize parameters\n",
    "threshold = 0.7 # control chunk tightness\n",
    "chunks = []\n",
    "current_chunk= []\n",
    "## Step 4: Semantic grouping based on threshold\n",
    "for i in range(1,len(sentences)):\n",
    "    sim = cosine_similarity(\n",
    "        [embeddings[i-1]],\n",
    "        [embeddings[i]]\n",
    "    )[0][0]\n",
    "\n",
    "    if sim>threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[i]]\n",
    "\n",
    "# Append the last chunk\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "#Output the chunks\n",
    "print(\"Semantic Chunks: \")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n{chunk}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03604624",
   "metadata": {},
   "source": [
    "### RAG Pipeline Modular Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0105097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.schema.runnable import RunnableLambda,RunnableMap\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Semantic Chunker with Threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self,model_name =\"all-MiniLM-L6-v2\",threshold=0.7):\n",
    "        self.model=SentenceTransformer(model_name)\n",
    "        self.threshold=threshold\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Pipelines (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
